{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week07_LogisticRegression",
      "provenance": [],
      "authorship_tag": "ABX9TyPnfMYCBD9ypdTqmCNGoWsU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Spring2022/blob/main/Week07_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxoN-gYypjZk"
      },
      "source": [
        "# Week 7\n",
        "# Logistic Regression\n",
        "\n",
        "We have studied how to use linear regression and polynomial regression to *predict a target numeric value*. There is another learning task, **classification**, aiming at predicting group membership rather than numeric values. Email spam filter is a good example: it is trained with many example emails with their class (spam or non-spam), and it must learn how to classify new emails.\n",
        "\n",
        "Linear regression is **not** a good choice for classification tasks. We will introduce the **logistic regression** model and use the iris dataset to illustrate how the model works.\n",
        "\n",
        "**Readings4**: Textbook Chapter 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taAvtt3jppKN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp3Dp0J5ppMc"
      },
      "source": [
        "## Logistic Regression: Intuition\n",
        "- Picture the data as points on the plane.\n",
        "- A classifier's job is to determine the decision regions for each class.\n",
        "- If a point is far from the decision boundary, then the classifier should be fairly confident about its prediction.\n",
        "- If a point is near the decision boundary, then the classifier may be less confident about its prediction.\n",
        "- The **logistic regression** model aims to provide a **probablity distribution** for each point. The probability distribution has little variance if the point is far from decision boundary.\n",
        "- **Probability distribution with high variance**: rolling a die - there is no way to predict the exact outcome\n",
        "- **Probability distribution with low variance**: getting the flu today - probably not going to happen\n",
        "\n",
        "<img src=\"https://mlr-org.com/docs/2015-07-28-Visualisation-of-predictions_files/figure-html/qda-1.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcy8l17zETEg"
      },
      "source": [
        "# Examples of low-variance probability distributions:\n",
        "[0.99, 0.001, 0.009] # low variance: the outcome most likely will be 1.\n",
        "[0.1, 0.8, 0.1] # low variance: the outcome most likely will be 2.\n",
        "\n",
        "# Examples of high-variance probability distributions:\n",
        "[0.333, 0.333, 0.334] # high variance\n",
        "[0.5, 0.5] # high variance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP_rRpctppO6"
      },
      "source": [
        "## Basic Case: Binary Classifier\n",
        "- Suppose there are only two classes for the output feature: **Class 0** (the negative class) and **Class 1** (the positive class).\n",
        "- A **binary classifer** tries to estimate the probability $p$ that a point belongs to Class 1.\n",
        "- The probability that a point belongs to Class 0 is $1 - p$.\n",
        "- Given the probability, the binary classifier will compare it with a chosen **threshold** (for example, 0.5), and then predict the class as\n",
        "    - prediction = 1 if $\\hat{p}$ $\\ge$ threshold\n",
        "    - prediction = 0 if $\\hat{p}$ < threshold\n",
        "- The **boundary** of decision regions is given by the curve formed by points whose probability equals to the threshold value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6kkVoPxppRZ"
      },
      "source": [
        "## Example: The Iris Dataset\n",
        "\n",
        "**Iris dataset** is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: Iris-Setosa, Iris-Versicolor, and Iris-Virginica. [wiki page](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
        "\n",
        "- Import dataset using <code>sklearn.dataset.load_iris()</code>\n",
        "- Explore the dataset: data description, feature names, data types, data histograms, scatter plots.\n",
        "- Split the dataset into train_set and test_set\n",
        "- Apply <code>sklearn.linear_model.LogisticRegression</code> to build a binary classifier on **Iris-Virginica**.\n",
        "- Evaluate the performance of the model: Accuracy, cross-validation, precision vs. recall, confusion matrix...\n",
        "- Visualize the model (show decision boundary)\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1000/1*Hh53mOF4Xy4eORjLilKOwA.png\" width=\"600\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "661QKVElppTu"
      },
      "source": [
        "# Load the dataset\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "iris.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR_7VatWppWA"
      },
      "source": [
        "# Description of the dataset\n",
        "print(iris['DESCR'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9I8J0yKppYd"
      },
      "source": [
        "print(iris['feature_names'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv0UuvJQppbE"
      },
      "source": [
        "# Convert the data into a data frame\n",
        "iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
        "iris_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3sutAZbppdx"
      },
      "source": [
        "# Add the target class\n",
        "iris_df['target'] = iris['target']\n",
        "iris_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAuak-RkppgZ"
      },
      "source": [
        "# Explore the dataset\n",
        "# How many examples are there for each type of Iris?\n",
        "\n",
        "iris_df['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-CL5tdlqxpX"
      },
      "source": [
        "# Find the min, max, mean, and median of each variable\n",
        "\n",
        "iris_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-OBcIvIJwVY"
      },
      "source": [
        "# Flower names are contained in the original iris object\n",
        "iris['target_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x29VUGKNppim"
      },
      "source": [
        "# Create a function that maps 0-2 to the actual type of iris\n",
        "def get_target_name(x):\n",
        "    return iris['target_names'][x]\n",
        "\n",
        "x = iris_df.loc[124, 'target']\n",
        "name = get_target_name(x)\n",
        "print(x, name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8ccjhHEpplM"
      },
      "source": [
        "# Apply get_target_name() to all target values\n",
        "iris_df['target_name'] = iris_df['target'].apply(get_target_name)\n",
        "iris_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rh5H4fGppn2"
      },
      "source": [
        "# Draw scatter plots.\n",
        "plt.scatter(iris_df.loc[:, 'sepal length (cm)'], iris_df.loc[:, 'sepal width (cm)'],\n",
        "            c=iris_df['target'])\n",
        "\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"sepal length\")\n",
        "plt.ylabel(\"sepal width\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwE-j7aPppqX"
      },
      "source": [
        "# Draw all scatter plots\n",
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(iris_df.iloc[:, :4], figsize=(15, 15), marker='o',\n",
        "               c=iris_df['target'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DbLrOEYpps9"
      },
      "source": [
        "## Build A Binary Classifier for Iris-Virginica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO4Wcfjappvi"
      },
      "source": [
        "# Define a function is_virginica(target) that returns 1 if target is Virginica\n",
        "# and 0 otherwise\n",
        "def is_virginica(target):\n",
        "\n",
        "    # if target == 2:\n",
        "    #     return 1\n",
        "    # else: \n",
        "    #     return 0\n",
        "    return int(target == 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edJ6tRU5ppyX"
      },
      "source": [
        "# Apply function is_virginica() to the data frame, creating a new \n",
        "# column \"Is_Virginica\"\n",
        "\n",
        "iris_df[\"Is_Virginica\"] = iris_df['target'].apply(is_virginica)\n",
        "iris_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJYPukLVpp01"
      },
      "source": [
        "# Train-test split\n",
        "# Split the data frame into 85% training data and 15% test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(iris_df, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiq_JIHkpp3X"
      },
      "source": [
        "# Display the amount of Virginica and non-Virginica cases in the training set and the test set\n",
        "# df_test['Is_Virginica'].value_counts()\n",
        "df_train['Is_Virginica'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5V5yex2T5CM"
      },
      "source": [
        "# Use a bar chart to show the number of cases\n",
        "df_train['Is_Virginica'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6jq2Luspp8a"
      },
      "source": [
        "# Build the logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(df_train.loc[:, ['sepal length (cm)',\n",
        "                           'sepal width (cm)',\n",
        "                           'petal length (cm)',\n",
        "                           'petal width (cm)']], df_train['Is_Virginica'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7zf8FQZU71M"
      },
      "source": [
        "# Since using .loc[] expression requires the full names of the columns, sometimes it\n",
        "# is easier to use their underlying integer indices in .iloc[] expression\n",
        "\n",
        "# For example, the expression \n",
        "# df_train.loc[:, ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
        "# is equivalent to\n",
        "# df_train.iloc[:, :4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj4tltViritD"
      },
      "source": [
        "## Model Evaluation\n",
        "- Classification accuracy\n",
        "- Cross Validation\n",
        "- Examine four categories using the confusion matrix:\n",
        "    - True Positive\n",
        "    - True Negative\n",
        "    - False Positive\n",
        "    - False Negative\n",
        "- Precision, recall, and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KT2AMrNrnfP"
      },
      "source": [
        "# 1. Find the prediction accuracy on test set\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "input_cols = ['sepal length (cm)',\n",
        "            'sepal width (cm)',\n",
        "            'petal length (cm)',\n",
        "            'petal width (cm)']\n",
        "\n",
        "# df_test.head()\n",
        "# get model's prediction on the test records\n",
        "test_predictions = model.predict(df_test.loc[:, input_cols])\n",
        "\n",
        "# model.predict(df_test.iloc[:, :4])\n",
        "\n",
        "accuracy_score(df_test['Is_Virginica'], test_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RUHEkBKYIxX"
      },
      "source": [
        "# Let's calculate the accuracy score without sklearn\n",
        "# Convert both Is_Virginica and predictions into numpy arrays\n",
        "array1 = np.array(df_test['Is_Virginica'])\n",
        "array2 = np.array(test_predictions)\n",
        "print(array1)\n",
        "print(array2)\n",
        "\n",
        "# Count the number of pairs that have identical values\n",
        "count = 0\n",
        "for i in range(len(array1)):\n",
        "    actual = array1[i]\n",
        "    pred = array2[i]\n",
        "    if actual == pred:\n",
        "        count = count + 1\n",
        "print(count)\n",
        "accuracy = count / len(array1)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGPP3YglZr3E"
      },
      "source": [
        "The accuracy score can be mislead. Consider the following scenario:\n",
        "- Suppose that the model returns 0 for any input.\n",
        "- Suppose that 99% of the test set are non-Virginica.\n",
        "- The accuracy score for this model on this particular test set will be: 0.99\n",
        "\n",
        "In order to make sure the model is indeed a good one, we need to examine its performance further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU1HcHmrsDja"
      },
      "source": [
        "# 2. confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(df_test['Is_Virginica'], test_predictions)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnlazoo8sKi3"
      },
      "source": [
        "<img src=\"https://hackernoon.com/hn-images/1*YV7zy1NGN1-HGQxY56nc_Q.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiXlzeYmsR6u"
      },
      "source": [
        "### 3. cross validation\n",
        "**Cross validation** is an efficient method that uses limited data to obtain multiple evaluations of the model.\n",
        "\n",
        "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4788946%2F82b5a41b6693a313b246f02d79e972d5%2FK%20FOLD.png?generation=1608195745131795&alt=media\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGIB1iprtGt3"
      },
      "source": [
        "# Perform 3-fold cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "input_cols = iris_df.columns[:4]\n",
        "print(cross_val_score(model, df_train[input_cols], df_train['Is_Virginica'],\n",
        "                      cv=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLwO2VqftUAT"
      },
      "source": [
        "### 4. Precision, Recall, and F-1 Score\n",
        "**Precision** and **recall** are two important metrics that evaluates different aspects of the model. **F-1 score** is a combination of the precision and recall.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3eFXvEstjiN"
      },
      "source": [
        "# precision - recall - f1 score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision = precision_score(df_test['Is_Virginica'], test_predictions) # How much Virigincia iris are correctly identified?\n",
        "recall = recall_score(df_test['Is_Virginica'], test_predictions) # How much Virginica predictions are correct?\n",
        "f1 = f1_score(df_test['Is_Virginica'], test_predictions)\n",
        "print(precision, recall, f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnkRYQ8CdoXT"
      },
      "source": [
        "# Calculate the scores ourselves.\n",
        "\n",
        "# First, we need the number of true positives, false positives, and false negatives.\n",
        "\n",
        "num_true_positives = 0\n",
        "for i in range(len(array1)):\n",
        "    label = array1[i]\n",
        "    pred = array2[i]\n",
        "    if label == 1 and pred == 1 :\n",
        "        num_true_positives = num_true_positives + 1\n",
        "print(num_true_positives)\n",
        "\n",
        "num_false_positives = 0\n",
        "for i in range(len(array1)):\n",
        "    label = array1[i]\n",
        "    pred = array2[i]\n",
        "    if label == 0 and pred == 1:\n",
        "        num_false_positives = num_false_positives + 1\n",
        "print(num_false_positives)\n",
        "\n",
        "precision = num_true_positives / (num_true_positives + num_false_positives)\n",
        "print(precision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBJIaBZ-ALAF"
      },
      "source": [
        "# Exercise: Calculate the recall score on your own.\n",
        "\n",
        "# Use a for loop to find the number of true positives\n",
        "num_true_positives = ???\n",
        "\n",
        "# Use a for loop to find the number of false negatives\n",
        "num_false_negatives = ???\n",
        "\n",
        "# Calculate recall: num_true_positives / (num_true_positives + num_false_negatives)\n",
        "recall = num_true_positives / (num_true_positives + num_false_negatives)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTGxG6GpCOGa"
      },
      "source": [
        "Consider the following scenario:\n",
        "- Suppose that the model returns 0 for any input.\n",
        "- Suppose that there are 99 non_Virginica and 1 Virginica in the test set.\n",
        "- num_true_positive: 0\n",
        "- num_false_positive: 0\n",
        "- num_false_negative: 1\n",
        "- precision: 0 / (0 + 0) --> undefined\n",
        "- recall: 0 / (0 + 1) --> 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmokZv2DDFCD"
      },
      "source": [
        "### F-1 Score: A Combination of Precision and Recall\n",
        "\n",
        "Since we expect the model to achieve high precision score and high recall score, we want to combine them into one score.\n",
        "\n",
        "- $F-1 score = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt1s58WQDg66"
      },
      "source": [
        "f1 = 2 / (1 / 0.875 + 1 / 1.0)\n",
        "print(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ERrWzpyEDjq"
      },
      "source": [
        "# high precision: 0.9\n",
        "# low recall: 0.1\n",
        "f1 = 2 / (1 / 0.9 + 1 / 0.1)\n",
        "print(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOxbFbGiELkT"
      },
      "source": [
        "# low precision: 0.1\n",
        "# high recall: 0.9\n",
        "f1 = 2 / (1 / 0.1 + 1 / 0.9)\n",
        "print(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTSROe7Mt5te"
      },
      "source": [
        "## Logistic Regression: Model Assumption\n",
        "**Binary classifier model**: Logistic regression model assumes that the decision boundary is represented as a linear function:\n",
        "\n",
        "$\\log\\frac{\\hat{p}}{1 - \\hat{p}} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n,$\n",
        "- n: number of input features.\n",
        "- $x_1, ..., x_n$: input features\n",
        "- $\\hat{p}$: the estimated probability of data belonging to the class\n",
        "- $\\theta_0,...,\\theta_n$: parameters of the model\n",
        "\n",
        "**Alternative format**:\n",
        "\n",
        "$\\hat{p} = \\sigma(\\textbf{x}\\cdot\\theta^T).$\n",
        "\n",
        "- $\\textbf{x} = (1, x_1, ..., x_n)$.\n",
        "- $\\theta = (\\theta_0, \\theta_1, ..., \\theta_n)$.\n",
        "- $\\sigma(t) = \\frac{1}{1+e^{-t}}$: logistic function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anlBy0OauLaV"
      },
      "source": [
        "# Plot the graph of logistic function\n",
        "\n",
        "# 1. Pick a list of x coordinates (`np.linspace`)\n",
        "x = np.linspace(-10, 10, 100)\n",
        "# 2. For each x, find the value of the function\n",
        "values = 1 / (1 + np.exp(-x)) # Since x is a numpy array, we can apply\n",
        "                                # np.exp directly\n",
        "# 3. plot the list of x coordinates and y coordinates using\n",
        "plt.plot(x, values, )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdQxqkj-uReO"
      },
      "source": [
        "## Logistic Regression: Decision Rule\n",
        "\n",
        "**Decision rule**: Pick a threshold (for example, 0.5), and then\n",
        "\n",
        "- prediction = 1 if $\\hat{p}$ $\\ge$ threshold\n",
        "- prediction = 0 if $\\hat{p}$ < threshold\n",
        "\n",
        "**Trade-off with threshold**:\n",
        "- If threshold is chosen closer to 1, then the positive predictions are __more likely__ to be correct (fewer **false positives**). However, the negative predictions are __less likely__ to be correct.\n",
        "- If threshold is chosen closer to 0, then the negative predictions are __more likely__ to be correct (fewer **false negatives**). However, the positive predictions are __less likely__ to be correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2RuK1ZfuUGO"
      },
      "source": [
        "## Logistic Regression: Cost Function and Training Algorithm\n",
        "For classification tasks, it is no longer appropriate to use MSE as the cost function.\n",
        "\n",
        "**Cost (loss) function** for logistic regression:\n",
        "\n",
        "\\begin{equation}\n",
        "c(\\theta) = \\left\\{\n",
        "\\begin{array}{cc}\n",
        "-\\log(\\hat{p}) & \\textit{if  }y=1,\\\\\n",
        "-\\log(1-\\hat{p}) & \\textit{if  }y=0.\n",
        "\\end{array}\n",
        "\\right.\n",
        "\\end{equation}\n",
        "\n",
        "The cost function $c(\\theta)$:\n",
        "\n",
        "- small if $y=1$ (data example belongs to the class) and $\\hat{p}$ is close to 1.\n",
        "- small if $y=0$ (data example does not belong to the class) and $\\hat{p}$ is close to 0.\n",
        "- is a convex function no matter what $y$ is.\n",
        "\n",
        "**Uniformed expression for the cost function**:\n",
        "\n",
        "$J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}\\big[y^{(i)}\\log(\\hat{p}^{(i)}) + (1-y^{(i)})\\log(1-\\hat{p}^{(i)})\\big]$\n",
        "\n",
        "- $c(\\theta) = J(\\theta)$ for $y=0$ and $y=1$.\n",
        "- There is no equivalent of the Normal Equation.\n",
        "- $J(\\theta)$ is a convex function, so the *gradient descent algorithm* will guarantee to find its global minimum.\n",
        "- $\\frac{\\partial J}{\\partial \\theta_j}=\\frac{1}{m}\\sum_{i=1}^{m}\\big(\\sigma(\\textbf{x}^{(i)}\\cdot\\theta^T) - y^{(i)}\\big)x_j^{(i)}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbg7vKt8vRk-"
      },
      "source": [
        "## Logistic Regression: Model Visualization\n",
        "- Create a grid of points from a list of x coordinates and y coordinates.\n",
        "- Use the model to obtain prediction probability on each point from the grid\n",
        "- Find points with marginal probabilities.\n",
        "- Plot the grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mUb3gXVvzaj"
      },
      "source": [
        "# Train a new logistic regression model on petal length and petal width only\n",
        "model2 = LogisticRegression(solver='lbfgs')\n",
        "model2.fit(df_train.iloc[:, 2:4], df_train['Is_Virginica'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "578Aekyrv1Jp"
      },
      "source": [
        "# 1. Create a grid of points\n",
        "x0, x1 = np.meshgrid(np.linspace(0, 7, 100),\n",
        "                     np.linspace(0, 2.7, 100))\n",
        "print(x0.shape, x1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMkv4u-Lv2_y"
      },
      "source": [
        "# Illustration of a meshgrid\n",
        "x_coordinates = [1, 2, 3, 4]\n",
        "y_coordinates = [10, 20, 30, 40]\n",
        "xx, yy = np.meshgrid(x_coordinates, y_coordinates)\n",
        "# print(xx)\n",
        "# print(yy)\n",
        "plt.plot(xx, yy, 'b.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIopn3Sgv-Ec"
      },
      "source": [
        "# 2. Obtain prediction probabilities\n",
        "X_new = np.hstack([x0.reshape([-1, 1]), x1.reshape([-1, 1])])\n",
        "y_new_prob = model2.predict_proba(X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f9UF-20wDDS"
      },
      "source": [
        "# 3. Find boundary points.\n",
        "# Which points give 0.5 probability?\n",
        "indices = np.where((y_new_prob[:, 1] > 0.49) & (y_new_prob[:, 1] < 0.51))\n",
        "X_boundary = X_new[indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3GzSTg_wENt"
      },
      "source": [
        "# 4. Plot the boundary\n",
        "plt.plot(X_boundary[:, 0], X_boundary[:, 1])\n",
        "index_virginica = (iris_df['Is_Virginica'] == 1)\n",
        "index_not_virginica = (iris_df['Is_Virginica'] == 0)\n",
        "plt.scatter(iris_df.loc[index_virginica, 'petal length (cm)'],\n",
        "            iris_df.loc[index_virginica, 'petal width (cm)'],\n",
        "            c='yellow',\n",
        "            label='Virginica')\n",
        "plt.scatter(iris_df.loc[index_not_virginica, 'petal length (cm)'],\n",
        "            iris_df.loc[index_not_virginica, 'petal width (cm)'],\n",
        "            c='purple',\n",
        "            label='Not Virginica')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GowAikpPwGUN"
      },
      "source": [
        "# 5. Plot probabilities\n",
        "plt.scatter(X_new[:, 0], X_new[:, 1], c=y_new_prob[:, 0])\n",
        "plt.colorbar()\n",
        "plt.scatter(iris_df.loc[index_virginica, 'petal length (cm)'],\n",
        "            iris_df.loc[index_virginica, 'petal width (cm)'],\n",
        "            c='yellow',\n",
        "            label='Virginica')\n",
        "plt.scatter(iris_df.loc[index_not_virginica, 'petal length (cm)'],\n",
        "            iris_df.loc[index_not_virginica, 'petal width (cm)'],\n",
        "            c='purple',\n",
        "            label='Not Virginica')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Multi-Class Classifier with Logistic Regression\n",
        "\n",
        "Now consider a classifier for more than 2 classes. Instead of outputting $p$ and $1-p$, this classifier will need to output $p_1, p_2, ..., p_n$, where $p_i$ is the probability of Class $i$. The output must satisfy:\n",
        "1. Each $p_i$ takes value in $[0, 1]$.\n",
        "2. The sum of all values must be 1.\n",
        "3. If the true class of an object is k, then we want $p_k\\approx 1$ and $p_i\\approx 0$ for all $i\\neq k$.\n",
        "\n",
        "Requirement 1 and 2 is guaranteed if we use the following **softmax** transformation:\n",
        "$$\n",
        "(t_1, t_2, ..., t_n) âŸ¶ (\\frac{e^{t_1}}{e^{t_1} + e^{t_2} +\\cdots + e^{t_n}}, \\frac{e^{t_2}}{e^{t_1} + e^{t_2} +\\cdots + e^{t_n}}, ..., \\frac{e^{t_n}}{e^{t_1} + e^{t_2} +\\cdots + e^{t_n}})\n",
        "$$"
      ],
      "metadata": {
        "id": "zlpThSQtwHyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Iris dataset as an example\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "iris_df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
        "iris_df['target'] = iris['target']\n",
        "iris_df.head()"
      ],
      "metadata": {
        "id": "C0wJ-BXgB3Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "input_cols = iris_df.columns[:4]\n",
        "model = LogisticRegression(solver=\"newton-cg\")\n",
        "model.fit(iris_df[input_cols], iris_df['target'])"
      ],
      "metadata": {
        "id": "7omVHxPbB5XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "predictions = model.predict(iris_df[input_cols])\n",
        "accuracy = accuracy_score(iris_df['target'], predictions)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "dGaMSM9lB7JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "23oPssuXB9TP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}